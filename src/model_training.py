"""
MÃ³dulo para treinamento de modelos de classificaÃ§Ã£o de credit score.
"""

import pandas as pd
import numpy as np
import mlflow
import mlflow.sklearn
import mlflow.xgboost
import mlflow.lightgbm
import mlflow.catboost
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
import lightgbm as lgb
from catboost import CatBoostClassifier
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
)
from mlflow.models import infer_signature
from data_preprocessing import load_and_preprocess_data, create_preprocessing_pipeline


def evaluate_and_log_classification_model(kind, model_name, pipeline, X_val, y_val):
    """
    FunÃ§Ã£o para avaliar e registrar modelos de classificaÃ§Ã£o
    
    Args:
        kind (str): Tipo do modelo (sklearn, xgboost, lightgbm, catboost)
        model_name (str): Nome do modelo
        pipeline: Pipeline treinado
        X_val: Features de validaÃ§Ã£o
        y_val: Target de validaÃ§Ã£o
        
    Returns:
        dict: DicionÃ¡rio com as mÃ©tricas calculadas
    """
    # Fazendo prediÃ§Ãµes
    predictions = pipeline.predict(X_val)
    prediction_proba = pipeline.predict_proba(X_val) if hasattr(pipeline, "predict_proba") else None
    
    # Calculando mÃ©tricas
    accuracy = accuracy_score(y_val, predictions)
    precision = precision_score(y_val, predictions, average='weighted')
    recall = recall_score(y_val, predictions, average='weighted')
    f1 = f1_score(y_val, predictions, average='weighted')
    
    # AUC-ROC para classificaÃ§Ã£o multiclasse
    if prediction_proba is not None:
        try:
            auc_roc = roc_auc_score(y_val, prediction_proba, multi_class='ovr', average='weighted')
        except:
            auc_roc = 0.0
    else:
        auc_roc = 0.0
    
    # Registrando mÃ©tricas no MLflow
    mlflow.log_metric("accuracy", accuracy)
    mlflow.log_metric("precision", precision)
    mlflow.log_metric("recall", recall)
    mlflow.log_metric("f1_score", f1)
    mlflow.log_metric("auc_roc", auc_roc)
    
    # Criando assinatura do modelo
    signature = infer_signature(X_val, predictions)
    
    # Registrando modelo baseado no tipo
    if kind == "catboost":
        mlflow.catboost.log_model(pipeline.named_steps['classifier'], model_name, signature=signature, input_example=X_val[:5])
    elif kind == "xgboost":
        mlflow.xgboost.log_model(pipeline.named_steps['classifier'], model_name, signature=signature, input_example=X_val[:5])
    elif kind == "lightgbm":
        mlflow.lightgbm.log_model(pipeline.named_steps['classifier'], model_name, signature=signature, input_example=X_val[:5])
    else:
        mlflow.sklearn.log_model(pipeline, model_name, signature=signature, input_example=X_val[:5])
    
    print(f"Modelo {model_name} avaliado:")
    print(f"  Accuracy: {accuracy:.4f}")
    print(f"  Precision: {precision:.4f}")
    print(f"  Recall: {recall:.4f}")
    print(f"  F1-Score: {f1:.4f}")
    print(f"  AUC-ROC: {auc_roc:.4f}")
    
    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
        'auc_roc': auc_roc
    }


def train_logistic_regression(X_train, y_train, X_val, y_val, preprocessor):
    """Treina modelo de RegressÃ£o LogÃ­stica"""
    with mlflow.start_run(run_name="Logistic Regression - Credit Score"):
        # Criando pipeline
        pipeline = Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('classifier', LogisticRegression(random_state=42, max_iter=1000))
        ])
        
        # Definindo parÃ¢metros para busca
        param_grid = {
            'classifier__C': [0.1, 1.0, 10.0],
            'classifier__solver': ['liblinear', 'lbfgs']
        }
        
        # Grid search
        grid_search = GridSearchCV(
            pipeline, param_grid, cv=5, 
            scoring='accuracy', n_jobs=-1
        )
        grid_search.fit(X_train, y_train)
        
        # Melhor modelo
        best_pipeline = grid_search.best_estimator_
        
        # Registrando melhores parÃ¢metros
        mlflow.log_param("best_C", grid_search.best_params_['classifier__C'])
        mlflow.log_param("best_solver", grid_search.best_params_['classifier__solver'])
        
        # Avaliando modelo
        metrics = evaluate_and_log_classification_model("sklearn", "logistic_regression", best_pipeline, X_val, y_val)
        
        return best_pipeline, metrics


def train_random_forest(X_train, y_train, X_val, y_val, preprocessor):
    """Treina modelo Random Forest"""
    with mlflow.start_run(run_name="Random Forest - Credit Score"):
        # Criando pipeline
        pipeline = Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('classifier', RandomForestClassifier(random_state=42))
        ])
        
        # Definindo parÃ¢metros para busca
        param_grid = {
            'classifier__n_estimators': [100, 200],
            'classifier__max_depth': [10, 20, None],
            'classifier__min_samples_split': [2, 5]
        }
        
        # Grid search
        grid_search = GridSearchCV(
            pipeline, param_grid, cv=3, 
            scoring='accuracy', n_jobs=-1
        )
        grid_search.fit(X_train, y_train)
        
        # Melhor modelo
        best_pipeline = grid_search.best_estimator_
        
        # Registrando melhores parÃ¢metros
        mlflow.log_param("best_n_estimators", grid_search.best_params_['classifier__n_estimators'])
        mlflow.log_param("best_max_depth", grid_search.best_params_['classifier__max_depth'])
        mlflow.log_param("best_min_samples_split", grid_search.best_params_['classifier__min_samples_split'])
        
        # Avaliando modelo
        metrics = evaluate_and_log_classification_model("sklearn", "random_forest", best_pipeline, X_val, y_val)
        
        return best_pipeline, metrics


def train_xgboost(X_train, y_train, X_val, y_val, preprocessor):
    """Treina modelo XGBoost"""
    with mlflow.start_run(run_name="XGBoost - Credit Score"):
        # Criando pipeline
        pipeline = Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('classifier', XGBClassifier(random_state=42, eval_metric='mlogloss'))
        ])
        
        # Definindo parÃ¢metros para busca
        param_grid = {
            'classifier__n_estimators': [100, 200],
            'classifier__max_depth': [3, 6],
            'classifier__learning_rate': [0.1, 0.2]
        }
        
        # Grid search
        grid_search = GridSearchCV(
            pipeline, param_grid, cv=3, 
            scoring='accuracy', n_jobs=-1
        )
        grid_search.fit(X_train, y_train)
        
        # Melhor modelo
        best_pipeline = grid_search.best_estimator_
        
        # Registrando melhores parÃ¢metros
        mlflow.log_param("best_n_estimators", grid_search.best_params_['classifier__n_estimators'])
        mlflow.log_param("best_max_depth", grid_search.best_params_['classifier__max_depth'])
        mlflow.log_param("best_learning_rate", grid_search.best_params_['classifier__learning_rate'])
        
        # Avaliando modelo
        metrics = evaluate_and_log_classification_model("xgboost", "xgboost_classifier", best_pipeline, X_val, y_val)
        
        return best_pipeline, metrics


def train_lightgbm(X_train, y_train, X_val, y_val, preprocessor):
    """Treina modelo LightGBM"""
    with mlflow.start_run(run_name="LightGBM - Credit Score"):
        # Criando pipeline
        pipeline = Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('classifier', lgb.LGBMClassifier(random_state=42, verbose=-1))
        ])
        
        # Definindo parÃ¢metros para busca
        param_grid = {
            'classifier__n_estimators': [100, 200],
            'classifier__max_depth': [3, 6],
            'classifier__learning_rate': [0.1, 0.2],
            'classifier__num_leaves': [31, 50]
        }
        
        # Grid search
        grid_search = GridSearchCV(
            pipeline, param_grid, cv=3, 
            scoring='accuracy', n_jobs=-1
        )
        grid_search.fit(X_train, y_train)
        
        # Melhor modelo
        best_pipeline = grid_search.best_estimator_
        
        # Registrando melhores parÃ¢metros
        mlflow.log_param("best_n_estimators", grid_search.best_params_['classifier__n_estimators'])
        mlflow.log_param("best_max_depth", grid_search.best_params_['classifier__max_depth'])
        mlflow.log_param("best_learning_rate", grid_search.best_params_['classifier__learning_rate'])
        mlflow.log_param("best_num_leaves", grid_search.best_params_['classifier__num_leaves'])
        
        # Avaliando modelo
        metrics = evaluate_and_log_classification_model("lightgbm", "lightgbm_classifier", best_pipeline, X_val, y_val)
        
        return best_pipeline, metrics


def main_random_forest_mlflow():
    """FunÃ§Ã£o para treinamento do Random Forest COM MLflow"""
    import dagshub
    
    print("ðŸŽ¯ TREINAMENTO ÃšNICO - RANDOM FOREST COM MLFLOW")
    print("âœ… APENAS 1 modelo serÃ¡ registrado no MLflow")
    print("âœ… SEM mÃºltiplos modelos")
    
    # ConfiguraÃ§Ã£o do MLflow (sem autolog para controle manual)
    dagshub.init(repo_owner="domires", repo_name="fiap-mlops-score-model", mlflow=True)
    mlflow.set_tracking_uri("https://dagshub.com/domires/fiap-mlops-score-model.mlflow")
    
    try:
        # Carregando dados usando caminhos alternativos
        try:
            train_processed, test_processed, features = load_and_preprocess_data(
                'references/exemplo_train.csv',
                'references/exemplo_test.csv'
            )
        except:
            # Fallback para outros caminhos possÃ­veis
            train_processed, test_processed, features = load_and_preprocess_data(
                'data/raw/train.csv',
                'data/raw/test.csv'
            )
    except Exception as e:
        print(f"âŒ Erro ao carregar dados: {e}")
        print("ðŸ’¡ Verifique se os arquivos de dados estÃ£o disponÃ­veis")
        return
    
    # Separando features e target
    X = train_processed[features]
    y = train_processed['Credit_Score']
    
    # Tratamento para target string (conversÃ£o automÃ¡tica)
    from sklearn.preprocessing import LabelEncoder
    if y.dtype == 'object':
        le = LabelEncoder()
        y_encoded = le.fit_transform(y)
        print(f"ðŸ”„ Target convertido: {le.classes_} â†’ {range(len(le.classes_))}")
    else:
        y_encoded = y
        le = None
    
    # Criando pipeline de prÃ©-processamento
    preprocessor = create_preprocessing_pipeline(X)
    
    # Dividindo dados para treino e validaÃ§Ã£o
    X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded)
    
    print(f"ðŸ“Š Dados preparados:")
    print(f"   Treino: {X_train.shape}")
    print(f"   ValidaÃ§Ã£o: {X_val.shape}")
    
    # Treinando APENAS Random Forest COM MLflow
    with mlflow.start_run(run_name="Random Forest - Credit Score (Ãšnico Modelo)"):
        print("\nðŸš€ Treinando Random Forest...")
        
        from sklearn.pipeline import Pipeline
        rf_pipeline = Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('classifier', RandomForestClassifier(
                n_estimators=150,
                max_depth=30,
                min_samples_split=2,
                min_samples_leaf=1,
                max_features='sqrt',
                random_state=42,
                class_weight='balanced',
                n_jobs=-1
            ))
        ])
        
        # Registrando parÃ¢metros no MLflow
        mlflow.log_param("model_type", "RandomForestClassifier")
        mlflow.log_param("n_estimators", 150)
        mlflow.log_param("max_depth", 30)
        mlflow.log_param("min_samples_split", 2)
        mlflow.log_param("min_samples_leaf", 1)
        mlflow.log_param("max_features", "sqrt")
        mlflow.log_param("class_weight", "balanced")
        mlflow.log_param("random_state", 42)
        
        # Treinar modelo
        rf_pipeline.fit(X_train, y_train)
        
        # Fazer prediÃ§Ãµes
        y_pred = rf_pipeline.predict(X_val)
        y_pred_proba = rf_pipeline.predict_proba(X_val)
        
        # Calcular mÃ©tricas
        accuracy = accuracy_score(y_val, y_pred)
        precision = precision_score(y_val, y_pred, average='weighted')
        recall = recall_score(y_val, y_pred, average='weighted')
        f1 = f1_score(y_val, y_pred, average='weighted')
        
        # Registrar mÃ©tricas no MLflow
        mlflow.log_metric("accuracy", accuracy)
        mlflow.log_metric("precision", precision)
        mlflow.log_metric("recall", recall)
        mlflow.log_metric("f1_score", f1)
        
        # Registrar modelo no MLflow
        from mlflow.models import infer_signature
        signature = infer_signature(X_val, y_pred)
        mlflow.sklearn.log_model(rf_pipeline, "random_forest_model", signature=signature)
        
        print(f"\nðŸ“Š RESULTADOS DO RANDOM FOREST:")
        print(f"   ðŸŽ¯ AcurÃ¡cia:  {accuracy:.4f} ({accuracy*100:.2f}%)")
        print(f"   ðŸŽ¯ PrecisÃ£o:  {precision:.4f}")
        print(f"   ðŸŽ¯ Recall:    {recall:.4f}")
        print(f"   ðŸŽ¯ F1-Score:  {f1:.4f}")
        
        # Salvar modelo localmente tambÃ©m
        import joblib
        import os
        os.makedirs('models', exist_ok=True)
        model_path = 'models/random_forest_credit_score.pkl'
        joblib.dump(rf_pipeline, model_path)
        
        if le:
            encoder_path = 'models/label_encoder.pkl'
            joblib.dump(le, encoder_path)
            print(f"âœ… Label encoder salvo: {encoder_path}")
        
        print(f"âœ… Modelo salvo localmente: {model_path}")
        print(f"âœ… Modelo registrado no MLflow!")
        print(f"âœ… APENAS 1 modelo Random Forest foi treinado!")


def main_random_forest_only():
    """FunÃ§Ã£o para treinamento APENAS do Random Forest (SEM MLflow)"""
    import joblib
    import os
    
    print("ðŸŽ¯ TREINAMENTO ÃšNICO - RANDOM FOREST")
    print("âœ… SEM MLflow (evita problemas de endpoint)")
    print("âœ… SEM mÃºltiplos modelos")
    
    try:
        # Carregando dados usando caminhos alternativos
        try:
            train_processed, test_processed, features = load_and_preprocess_data(
                'references/exemplo_train.csv',
                'references/exemplo_test.csv'
            )
        except:
            # Fallback para outros caminhos possÃ­veis
            train_processed, test_processed, features = load_and_preprocess_data(
                'data/raw/train.csv',
                'data/raw/test.csv'
            )
    except Exception as e:
        print(f"âŒ Erro ao carregar dados: {e}")
        print("ðŸ’¡ Verifique se os arquivos de dados estÃ£o disponÃ­veis")
        return
    
    # Separando features e target
    X = train_processed[features]
    y = train_processed['Credit_Score']
    
    # Tratamento para target string (conversÃ£o automÃ¡tica)
    from sklearn.preprocessing import LabelEncoder
    if y.dtype == 'object':
        le = LabelEncoder()
        y_encoded = le.fit_transform(y)
        print(f"ðŸ”„ Target convertido: {le.classes_} â†’ {range(len(le.classes_))}")
    else:
        y_encoded = y
        le = None
    
    # Criando pipeline de prÃ©-processamento
    preprocessor = create_preprocessing_pipeline(X)
    
    # Dividindo dados para treino e validaÃ§Ã£o
    X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded)
    
    print(f"ðŸ“Š Dados preparados:")
    print(f"   Treino: {X_train.shape}")
    print(f"   ValidaÃ§Ã£o: {X_val.shape}")
    
    # Treinando APENAS Random Forest (sem MLflow)
    print("\nðŸš€ Treinando Random Forest...")
    
    from sklearn.pipeline import Pipeline
    rf_pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', RandomForestClassifier(
            n_estimators=150,
            max_depth=30,
            min_samples_split=2,
            min_samples_leaf=1,
            max_features='sqrt',
            random_state=42,
            class_weight='balanced',
            n_jobs=-1
        ))
    ])
    
    # Treinar modelo
    rf_pipeline.fit(X_train, y_train)
    
    # Fazer prediÃ§Ãµes
    y_pred = rf_pipeline.predict(X_val)
    
    # Calcular mÃ©tricas
    accuracy = accuracy_score(y_val, y_pred)
    precision = precision_score(y_val, y_pred, average='weighted')
    recall = recall_score(y_val, y_pred, average='weighted')
    f1 = f1_score(y_val, y_pred, average='weighted')
    
    print(f"\nðŸ“Š RESULTADOS DO RANDOM FOREST:")
    print(f"   ðŸŽ¯ AcurÃ¡cia:  {accuracy:.4f} ({accuracy*100:.2f}%)")
    print(f"   ðŸŽ¯ PrecisÃ£o:  {precision:.4f}")
    print(f"   ðŸŽ¯ Recall:    {recall:.4f}")
    print(f"   ðŸŽ¯ F1-Score:  {f1:.4f}")
    
    # Salvar modelo
    os.makedirs('models', exist_ok=True)
    model_path = 'models/random_forest_credit_score.pkl'
    joblib.dump(rf_pipeline, model_path)
    
    if le:
        encoder_path = 'models/label_encoder.pkl'
        joblib.dump(le, encoder_path)
        print(f"âœ… Label encoder salvo: {encoder_path}")
    
    print(f"âœ… Modelo salvo: {model_path}")
    print(f"âœ… APENAS 1 modelo Random Forest foi treinado!")


def main():
    """FunÃ§Ã£o principal para treinamento APENAS do Random Forest com MLflow"""
    import dagshub
    
    # ConfiguraÃ§Ã£o do MLflow (sem autolog para controle manual)
    dagshub.init(repo_owner="domires", repo_name="fiap-mlops-score-model", mlflow=True)
    mlflow.set_tracking_uri("https://dagshub.com/domires/fiap-mlops-score-model.mlflow")
    
    try:
        # Carregando dados usando caminhos alternativos
        try:
            train_processed, test_processed, features = load_and_preprocess_data(
                'references/exemplo_train.csv',
                'references/exemplo_test.csv'
            )
        except:
            # Fallback para outros caminhos possÃ­veis
            train_processed, test_processed, features = load_and_preprocess_data(
                'data/raw/train.csv',
                'data/raw/test.csv'
            )
    except Exception as e:
        print(f"âŒ Erro ao carregar dados: {e}")
        print("ðŸ’¡ Verifique se os arquivos de dados estÃ£o disponÃ­veis")
        return
    
    # Separando features e target
    X = train_processed[features]
    y = train_processed['Credit_Score']
    
    # Tratamento para target com valores NaN
    if y.isna().sum() > 0:
        print(f"ðŸ”„ Convertendo {y.isna().sum()} valores NaN no target para 'Unknown'")
        y = y.fillna('Unknown')
    
    # Tratamento para target string (conversÃ£o automÃ¡tica)
    from sklearn.preprocessing import LabelEncoder
    if y.dtype == 'object':
        le = LabelEncoder()
        y_encoded = le.fit_transform(y)
        print(f"ðŸ”„ Target convertido: {le.classes_} â†’ {range(len(le.classes_))}")
    else:
        y_encoded = y
        le = None
    
    # Criando pipeline de prÃ©-processamento
    preprocessor = create_preprocessing_pipeline(X)
    
    # Dividindo dados para treino e validaÃ§Ã£o
    X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded)
    
    print(f"ðŸ“Š Dados preparados:")
    print(f"   X_train: {X_train.shape}, y_train: {y_train.shape}")
    print(f"   X_val: {X_val.shape}, y_val: {y_val.shape}")
    
    # Treinando APENAS Random Forest COM MLflow
    try:
        print("\nðŸš€ Treinando Random Forest...")
        model, metrics = train_random_forest(X_train, y_train, X_val, y_val, preprocessor)
        
        # Salvar modelo localmente tambÃ©m
        import joblib
        import os
        os.makedirs('models', exist_ok=True)
        model_path = 'models/random_forest_credit_score.pkl'
        joblib.dump(model, model_path)
        
        if le:
            encoder_path = 'models/label_encoder.pkl'
            joblib.dump(le, encoder_path)
            print(f"âœ… Label encoder salvo: {encoder_path}")
        
        print(f"âœ… Modelo salvo localmente: {model_path}")
        
        # Resumo dos resultados
        print("\n=== RESULTADOS DO RANDOM FOREST ===")
        for metric_name, value in metrics.items():
            print(f"  {metric_name}: {value:.4f}")
        
        print("\nâœ… Treinamento concluÃ­do! Modelo registrado no MLflow.")
        
    except Exception as e:
        print(f"Erro no treinamento do Random Forest: {e}")
        raise


if __name__ == "__main__":
    main()